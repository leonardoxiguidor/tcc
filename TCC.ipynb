{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8071a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "from functools import lru_cache\n",
    "import random\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://root:root@localhost:3306/tcc\")\n",
    "\n",
    "def dias_uteis_entre_datas(data_inicial, data_final, feriados=None):\n",
    "    \n",
    "    # Datas em que não houve pregão na B3 por motivos especiais desde 2000\n",
    "    datas_sem_pregao = [\n",
    "        '2001-09-12', '2002-06-17', '2002-06-21', '2002-06-26', '2002-06-30',\n",
    "        '2006-06-27', '2006-06-30', '2010-06-25', '2014-06-12', '2014-06-17',\n",
    "        '2014-06-23', '2014-06-28', '2014-07-04', '2018-06-22', '2018-06-27',\n",
    "        '2018-07-02', '2018-07-06'\n",
    "    ]\n",
    "\n",
    "    feriados = datas_sem_pregao if feriados is None else feriados + datas_sem_pregao\n",
    "\n",
    "    # Lista de feriados nacionais brasileiros fixos\n",
    "    feriados_fixos = ['01-01', '04-21', '05-01', '09-07', '10-12', '11-02', '11-15', '12-25']\n",
    "    \n",
    "    data_inicial = np.datetime64(data_inicial)\n",
    "    data_final = np.datetime64(data_final)\n",
    "    anos = list(range(data_inicial.astype('M8[Y]').astype(int) + 1970, data_final.astype('M8[Y]').astype(int) + 1971))\n",
    "    \n",
    "    for ano in anos:\n",
    "        for feriado_fixo in feriados_fixos:\n",
    "            feriados.append(f\"{ano}-{feriado_fixo}\")\n",
    "    \n",
    "    feriados = [np.datetime64(feriado) for feriado in feriados]\n",
    "    datas = np.arange(data_inicial, data_final + np.timedelta64(1, 'D'))\n",
    "    dias_uteis = np.is_busday(datas)\n",
    "    \n",
    "    for feriado in feriados:\n",
    "        dias_uteis &= (datas != feriado)\n",
    "\n",
    "    return np.sum(dias_uteis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b067a1",
   "metadata": {},
   "source": [
    "# Implementação Grafo de Visibilidade\n",
    "\n",
    "Nessa seção fazemos a implementação da geração do grafo de visibilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922dd62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que transforma uma lista de conexões em um grafo\n",
    "def list_to_graph(connections):\n",
    "    graph = nx.Graph()\n",
    "    graph.add_edges_from(connections)\n",
    "    return graph\n",
    "\n",
    "# Função que transforma um grafo em uma lista de conexões\n",
    "def graph_to_list(graph):\n",
    "    return [sorted(list(i)) for i in list(graph.edges())]\n",
    "\n",
    "# Função que transforma uma série temporal em um grafo de visibilidade\n",
    "def visibility_graph(time_series):\n",
    "\n",
    "    n = len(time_series)\n",
    "    graph = nx.Graph()\n",
    "\n",
    "    for i in range(n):\n",
    "        graph.add_node(i)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if all((time_series[j]-time_series[i])/(j-i) > (time_series[k]-time_series[i])/(k-i) for k in range(i+1, j)):\n",
    "                graph.add_edge(i, j)\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "def plot_graph(graph, time_series):\n",
    "\n",
    "    pos = {i: (i, y) for i, y in enumerate(time_series)}\n",
    "    nx.draw(graph, pos, with_labels=False, node_color='red', edge_color='gray')\n",
    "    plt.show()\n",
    "    \n",
    "# Função que a partir do código do ativo, uma data inicial e uma data final, retorna um grafo com os nodos normalizados\n",
    "def grafo(ativo, dataA, dataB):\n",
    "    query = f'''SELECT nodoA, nodoB \n",
    "    FROM grafos_conexoes \n",
    "    WHERE ativo = '{ativo}' AND dataA >= '{dataA}' AND dataB <= '{dataB}'\n",
    "    ORDER BY dataA ASC;'''\n",
    "    \n",
    "    connections = list(engine.execute(query).fetchall())\n",
    "    \n",
    "    return list_to_graph([(i[0]-connections[0][0]+1, i[1] -connections[0][0]+1) for i in connections])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c9352",
   "metadata": {},
   "source": [
    "# Similaridades \n",
    "\n",
    "Implementações de cada método testado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementação da GED para o contexto do trabalho: basicamente conta a quantidade de arestas incomuns aos grafos, que são as arestas a serem removidas/adicionadas para igualar os grafos.\n",
    "\n",
    "def GED(graph1,graph2, n):\n",
    "    edges1 = set([tuple(sorted(list(i))) for i in list(graph1.edges())])\n",
    "    edges2 = set([tuple(sorted(list(i))) for i in  list(graph2.edges())])\n",
    "    \n",
    "    intersection = len(edges1.intersection(edges2))\n",
    "    union = len(edges1.union(edges2))\n",
    "    \n",
    "    d = union - intersection\n",
    "    \n",
    "    return n/(n+d)\n",
    "\n",
    "def frobenius_distance(graph1, graph2, n = 1):\n",
    "\n",
    "    A1 = nx.adjacency_matrix(graph1, nodelist=range(1, n+1)).toarray()\n",
    "    A2 = nx.adjacency_matrix(graph2, nodelist=range(1, n+1)).toarray()\n",
    "    \n",
    "    \n",
    "    diff = A1 - A2\n",
    "\n",
    "    return (n-np.linalg.norm(diff))/n\n",
    "\n",
    "def jaccard_coefficient(graph1, graph2):\n",
    "\n",
    "    edges1 = set([tuple(sorted(list(i))) for i in list(graph1.edges())])\n",
    "    edges2 = set([tuple(sorted(list(i))) for i in  list(graph2.edges())])\n",
    "    \n",
    "    intersection = len(edges1.intersection(edges2))\n",
    "    union = len(edges1.union(edges2))\n",
    "    \n",
    "    return intersection / union if union != 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99e9da6",
   "metadata": {},
   "source": [
    "# Simulação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9905a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que calcula a média móvel da similaridade\n",
    "def media_movel_dupla(grupo, tamanho_media):\n",
    "    media_movel = pd.Series([0] * len(grupo), index=grupo.index)\n",
    "\n",
    "    if len(grupo) > tamanho_media:\n",
    "        media_movel[tamanho_media:] = grupo['similaridade'].rolling(window=tamanho_media, min_periods=1).mean()[tamanho_media:]\n",
    "\n",
    "    return media_movel\n",
    "\n",
    "# Função que extrai e trata os dados necessários para a simulação \n",
    "def get_data(limiar_var, data_inicial, data_final, n, metodo, tamanho_media): \n",
    "    \n",
    "    query = f'''SELECT data, ativo, fechamento FROM dados_diarios_b3 WHERE data BETWEEN '{data_inicial}' AND '{data_final}';'''\n",
    "\n",
    "    dados_diarios_b3 = pd.read_sql(query, engine)\n",
    "\n",
    "    query = f'''SELECT *, \n",
    "    (IF(var >= -{limiar_var} AND var <= {limiar_var}, 'L', IF(var > {limiar_var}, 'A', 'B'))) AS estado\n",
    "    FROM grafos \n",
    "    WHERE dataFinal BETWEEN '{data_inicial}' AND '{data_final}' AND n = {n} AND incluso = 1\n",
    "    ORDER BY ativo,  dataFinal ASC;'''\n",
    "    grafos = pd.read_sql(query,engine)\n",
    "\n",
    "    grafos['transicao'] = grafos.groupby('ativo')['estado'].shift(1) != grafos['estado']\n",
    "    grafos['transicao'] = grafos['transicao'].apply(lambda x: 1 if x else 0)\n",
    "    grafos['transicao'] = grafos['transicao'].fillna(0)\n",
    "\n",
    "\n",
    "    datas = grafos.sort_values(['dataFinal'], ascending = True)['dataFinal'].unique()\n",
    "\n",
    "    query = f'''SELECT gA.dataFinal AS dataFinal, \n",
    "    similaridades.idGrafoA, \n",
    "    gA.ativo AS ativoA, \n",
    "    (IF(gA.var >= -{limiar_var} AND gA.var <= {limiar_var}, 'L', IF(gA.var > {limiar_var}, 'A', 'B'))) AS estadoA,\n",
    "    similaridades.idGrafoB, \n",
    "    gB.ativo AS ativoB, \n",
    "    (IF(gB.var >= -{limiar_var} AND gB.var <= {limiar_var}, 'L', IF(gB.var  > {limiar_var}, 'A', 'B'))) AS estadoB,\n",
    "    similaridades.{metodo} AS similaridade\n",
    "    FROM similaridades \n",
    "    LEFT JOIN grafos AS gA ON similaridades.idGrafoA = gA.id \n",
    "    LEFT JOIN grafos AS gB ON similaridades.idGrafoB = gB.id\n",
    "    WHERE similaridades.idGrafoA IN {tuple(grafos['id'].unique())} \n",
    "    OR similaridades.idGrafoB IN {tuple(grafos['id'].unique())};'''\n",
    "    similaridades = pd.read_sql(query, engine)\n",
    "\n",
    "    similaridades['similaridade'] = similaridades.apply(lambda x: -x['similaridade'] if ((x['estadoA'] == 'B' and x['estadoB'] == 'A') or (x['estadoA'] == 'A' and x['estadoB'] == 'B')) else x['similaridade'], axis = 1)\n",
    "    similaridades['similaridadeMedia'] = 0\n",
    "\n",
    "\n",
    "    for (ativoA, ativoB), grupo in similaridades.groupby(['ativoA', 'ativoB']):\n",
    "        similaridades.loc[grupo.index, 'similaridadeMedia'] = media_movel_dupla(grupo, tamanho_media)\n",
    "\n",
    "    return dados_diarios_b3, grafos, datas, similaridades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "852e8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que processa a simulação\n",
    "def processing(dados_diarios_b3, grafos, datas, qtd_sinais, sim_min, similaridades, tamanho_media, limiar_var, concentracao_max):\n",
    "    caixa = 1\n",
    "    carteira = {}\n",
    "    transacoes = []\n",
    "    trades = 0\n",
    "    trades_assertivos = 0\n",
    "\n",
    "    \n",
    "    grafos_agrupados = grafos.groupby('dataFinal')\n",
    "    similaridades_agrupadas = similaridades.groupby('dataFinal')\n",
    "\n",
    "    for data in datas[tamanho_media:]:\n",
    "        if data in grafos_agrupados.groups and data in similaridades_agrupadas.groups:\n",
    "            grafos_data = grafos_agrupados.get_group(data)\n",
    "            similaridades_data = similaridades_agrupadas.get_group(data)\n",
    "            ativos_data = grafos_data['ativo'].unique()\n",
    "            \n",
    "            sinais_compra_data = []\n",
    "\n",
    "            for ativo in ativos_data:\n",
    "                correlacionados_data = similaridades_data[(similaridades_data['similaridadeMedia'] >= sim_min) & ((similaridades_data['ativoA'] == ativo) | (similaridades_data['ativoB'] == ativo))]\n",
    "                correlacionados = set(correlacionados_data['ativoA'].unique()).union(set(correlacionados_data['ativoB'].unique()))\n",
    "\n",
    "                sinais_compra = grafos_data[grafos_data['ativo'].isin(correlacionados) & (grafos_data['estado'] == 'A')]['transicao'].sum()\n",
    "                sinais_venda = grafos_data[grafos_data['ativo'].isin(correlacionados) & (grafos_data['estado'] == 'B')]['transicao'].sum()\n",
    "\n",
    "                if (ativo not in carteira) and (sinais_compra - sinais_venda >= qtd_sinais):\n",
    "                    sinais_compra_data.append({\"ativo\": ativo, \"qtd\": sinais_compra - sinais_venda})\n",
    "\n",
    "                elif (ativo in carteira) and (sinais_venda - sinais_compra >= qtd_sinais):\n",
    "                    var = dados_diarios_b3[(dados_diarios_b3['ativo'] == ativo) & (dados_diarios_b3['data'] == data)]['fechamento'].iloc[0] / dados_diarios_b3[(dados_diarios_b3['ativo'] == ativo) & (dados_diarios_b3['data'] == carteira[ativo]['data'])]['fechamento'].iloc[0]\n",
    "                    valor_venda = carteira[ativo]['qtd'] * var\n",
    "                    caixa += valor_venda\n",
    "\n",
    "                    transacoes.append({\"tipo\": \"venda\", \"ativo\": ativo, \"data\": data, \"sinais\": sinais_venda - sinais_compra, \"valor\": valor_venda, 'rentabilidade': round(var - 1, 4)})\n",
    "                    carteira.pop(ativo)\n",
    "\n",
    "                    trades += 1\n",
    "                    if var - 1 > limiar_var:\n",
    "                        trades_assertivos += 1\n",
    "\n",
    "            if sinais_compra_data:\n",
    "                sinais_compra_data_df = pd.DataFrame(sinais_compra_data).sort_values(by='qtd', ascending=False)\n",
    "                sinais_compra_data = sinais_compra_data_df.to_dict(orient='records')\n",
    "\n",
    "                for sinal in sinais_compra_data:\n",
    "                    if caixa > 0:\n",
    "                        valor_investimento = concentracao_max if caixa - concentracao_max >= 0 else caixa\n",
    "                        transacoes.append({\"tipo\": \"compra\", \"ativo\": sinal['ativo'], \"data\": data, \"sinais\": sinal['qtd'], \"valor\": valor_investimento, 'rentabilidade': '-'})\n",
    "                        caixa -= valor_investimento\n",
    "                        carteira[sinal['ativo']] = {\"data\": data, \"qtd\": valor_investimento}\n",
    "                        continue\n",
    "                    break\n",
    "\n",
    "    ultima_data = datas[-1]\n",
    "\n",
    "    for ativo in carteira:\n",
    "        var = dados_diarios_b3[(dados_diarios_b3['ativo'] == ativo) & (dados_diarios_b3['data'] == ultima_data)]['fechamento'].iloc[0] / dados_diarios_b3[(dados_diarios_b3['ativo'] == ativo) & (dados_diarios_b3['data'] == carteira[ativo]['data'])]['fechamento'].iloc[0]\n",
    "        valor_venda = carteira[ativo]['qtd'] * var\n",
    "        caixa += valor_venda\n",
    "\n",
    "        transacoes.append({\"tipo\": \"venda\", \"ativo\": ativo, \"data\": data, \"sinais\": 0, \"valor\": valor_venda, 'rentabilidade': round(var - 1, 4)})\n",
    "\n",
    "    return transacoes, trades, trades_assertivos, round((caixa - 1), 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "331bb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que une a extração de dados ao processamento\n",
    "\n",
    "def simulacao(n, metodo, qtd_sinais, sim_min, tamanho_media, data_inicial, data_final, limiar_var = 0.0015, concentracao_max = 0.1):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    dados_diarios_b3, grafos, datas, similaridades = get_data(limiar_var, data_inicial, data_final, n, metodo, tamanho_media)\n",
    "    \n",
    "    transacoes, trades, trades_assertivos, rentabilidade = processing(dados_diarios_b3, grafos, datas, qtd_sinais, sim_min, similaridades, tamanho_media, limiar_var, concentracao_max)\n",
    "    \n",
    "    tempo = round(time.time()-start, 2)\n",
    "    \n",
    "    print('----------------------------------RESULTADOS----------------------------------')\n",
    "    print('Número de Trades: ', trades)\n",
    "    print('Número de Trades Assertivos: ', trades_assertivos, f' - Assertividade {round(100*(trades_assertivos/trades if trades else 0), 2)}%')\n",
    "    print(f'Rentabilidade {round(100*rentabilidade, 2)}%')\n",
    "    print(f'Tempo total da simulação: {tempo} segundos')\n",
    "    \n",
    "    return transacoes, trades, trades_assertivos, rentabilidade, tempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a892fed0",
   "metadata": {},
   "source": [
    "# Testando Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c7dfae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metodos = ['sJaccard', 'sFrobenius', 'sEdicao']\n",
    "ns = [5, 10, 25, 35, 50]\n",
    "tamanhos_media = [5, 10, 15]\n",
    "concentracoes_max = [0.1, 0.075, 0.05]\n",
    "qtds_minima_sinais = [3, 5, 7, 10]\n",
    "similaridades_minimas = [0.65, 0.75, 0.85, 0.9]\n",
    "\n",
    "def gerar_combinacoes_aleatorias(num_combinacoes):\n",
    "    combinacoes = []\n",
    "    for _ in range(num_combinacoes):\n",
    "        combinacao = {\n",
    "            'metodo': random.choice(metodos),\n",
    "            'n': random.choice(ns),\n",
    "            'tamanho_media': random.choice(tamanhos_media),\n",
    "            'janela': random.choice(janelas),\n",
    "            'concentracao_max': random.choice(concentracoes_max),\n",
    "            'qtd_minima_sinais': random.choice(qtds_minima_sinais),\n",
    "            'similaridade_minima': random.choice(similaridades_minimas)\n",
    "        }\n",
    "        combinacoes.append(combinacao)\n",
    "    return combinacoes\n",
    "\n",
    "combinacoes_aleatorias = gerar_combinacoes_aleatorias(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d59bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testa(combinacao): \n",
    "    \n",
    "    transacoes, trades, trades_assertivos, rentabilidade, tempo = simulacao(\n",
    "        combinacao['n'],\n",
    "        combinacao['metodo'],\n",
    "        combinacao['qtd_minima_sinais'],\n",
    "        combinacao['similaridade_minima'],\n",
    "        combinacao['tamanho_media'],\n",
    "        combinacao['janela']['dataInicial'],\n",
    "        combinacao['janela']['dataFinal'],\n",
    "        concentracao_max=combinacao['concentracao_max']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    if trades > 0:\n",
    "    \n",
    "        resultado_df = pd.DataFrame([{\n",
    "            'n': combinacao['n'],\n",
    "            'metodo': combinacao['metodo'],\n",
    "            'qtd_minima_sinais': combinacao['qtd_minima_sinais'],\n",
    "            'similaridade_minima': combinacao['similaridade_minima'],\n",
    "            'tamanho_media': combinacao['tamanho_media'],\n",
    "            'data_inicial': combinacao['janela']['dataInicial'],\n",
    "            'data_final': combinacao['janela']['dataFinal'],\n",
    "            'limiar_variacao': 0.0015,\n",
    "            'concentracao_max': combinacao['concentracao_max'],\n",
    "            'numero_trades': trades,\n",
    "            'numero_trades_assertivos': trades_assertivos,\n",
    "            'rentabilidade': rentabilidade,\n",
    "            'tempo_simulacao': tempo,\n",
    "            'transacoes': str(transacoes)\n",
    "        }])\n",
    "\n",
    "        resultado_df.to_sql('simulacoes', engine, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f55b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for combinacao in combinacoes_aleatorias: \n",
    "    testa(combinacao)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
